# Dreamspace Co-Pilot: AI + BCI Co-Piloted Visual Dreamspace

## Overview

Dreamspace Co-Pilot is a hybrid Brain-Computer Interface (BCI) and Artificial Intelligence (AI) system that enables users to co-pilot and explore imaginative visual experiences in a way that feels like a dream: semi-intentional, emotionally responsive, yet partially out of one's control. The system blends generative visual models (e.g., Kandinsky 2.1, Stable Diffusion) with passive and active EEG-based BCI signals to steer imagery in latent space, allowing users to influence the unfolding of story-like or symbolic visual narratives. An AI co-pilot spins a narrative which drives the overall arch of the image sequence, and much like in a dream, the human user may not be aware of that narrative, but simply experiences it as a shift of themes throughout the sequence. The AI does not reveal the narrative until after the session.

## Key Features

- üîÆ **Latent-space continuity**: Images evolve gradually to maintain narrative and visual cohesion.
- üß† **EEG/BCI input support**: Use EEG signals or manual keyboard proxies to steer the generation.
- ‚ú® **LLM-driven storytelling**: Asynchronous prompts update the narrative and influence image evolution.
- üñºÔ∏è **Diffusion-based generation**: Uses models like Kandinsky 2.1 or Stable Diffusion via Hugging Face.
- üß™ **Exploratory modes**: Switch between different control paradigms ‚Äî e.g., prompt morphing, latent vector traversal, img2img evolution.

